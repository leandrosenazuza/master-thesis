\chapter{Fundamentação Teórica}

\section{Subestações de Energia}
\label{sec:subestacao}

A energia elétrica no Brasil é oriunda majoritariamente de fontes renováveis, em especial da geração hidroelétrica, correspondendo a 69\% de toda malha produtora. Esta forma de gerar energia é limpa, de baixo custo e possui reduzidaemissão de gases de efeito estufa \cite{de2015hydroelectric}. 

Após a geração, a energia passa pelo processo de transmissão, que será responsável por aplicar as devidas transformações, para que a eletricidade chegue em níveis seguros e desejados para o consumidor final. É nesta etapa que são usadas as subestações de energia. Trata-se, basicamente, de um sítio industrial, equipado com diversas máquinas, cujo objetivo é alterar e redirecionar a tensões elétricas, assim como manter íntegro e seguro todo esse processo de transferência. Para que isso ocorra, o processo inicial é realizado em altíssimas tensões, para que seja reduzida a perda durante o processo; assim como próximo aos consumidores finais, a tensão é reduzida para valores apropriados para uso doméstico \cite {muzysubestaccoes}.

De maneira mais aprofundada, a energia é, portanto, obtida por geradores e transmitida para subestações primárias. Há aí a primeira aferição de qualidade dos níveis de transmissão. Após isso, a energia transformada é enviada para subestações de distribuição, alterada para níveis mais baixos para serem transmitidas para setores industriais e urbanos \cite{barreto2022proposta}.

\section{Redes Neurais Artificiais}
\label{sec:redesneurais}

A RNA trata-se de um conjunto de técnicas que buscam simular o funcionamento do cérebro humano, a partir de algoritmos computacionais, a fim de resolver problemas específicos. Sua eficiência está relacionada com a quantidade de interações que as unidades de processamento que o compõem realizam entre si. Comparam-se as RNA à mente humana devido a sua capacidade de aprendizado, podendo generalizar funções a partir de alguns exemplos informados, e delas prever o comportamento de valores para os quais não foi fornecido a resposta esperada. A base do funcionamento da RNA está no conceito do neurônio artificial (NA), que se traduz como uma pequena unidade de processamento, capaz de receber um sinal simples, e a partir dele gerar uma resposta.  De acordo com  \cite{fleck2016redes}, a primeira noção de NA surge em 1943, no trabalho Warren McCulloch e Walter Pitts, no artigo: “A Logical Calculus of the Ideas Immanent in Nervous Activity”.

Matematicamente, o NA recebe um valor de entrada, realizando com ele o produto desse valor a um outro denominado peso. O resultado é comparado com um diferenciador: se for maior, será dada a saída verdadeira; se menor, falso. Na figura \ref{fig:na}, esse processo é demonstrado de maneira esquemática. A operação descrita, chamada também de threshold logic, i.e., lógica limiar, em tradução livre, mimetiza o funcionamento de um componente eletrônico chamado transistor, base do funcionamento dos processadores computacionais modernos, em que a passagem de corrente elétrica por ele é interrompida ou permitida com base no sinal de entrada \cite {mcculloch1943logical}. 

\begin{figure}[!h]
    \centering
    \begin{minipage}{0.9\linewidth}
    \centering
    \captionsetup{justification=centering,margin=0.5cm,font=small}
    \includegraphics[width=0.7\linewidth]{img/cap2/na-completo.png}
    \caption{Representação de um NA \cite{adorno2017}}.
    \label{fig:na}
    \end{minipage}
\end{figure}

Aprofundando-se na álgebra relacionada do NA, pode-se visualizar o esquema do seu funcionamento na figura \ref{fig:na}, e também acompanhar a definição de cada envolvido nesta operação \cite{deeplearningbook2023}:

\begin{itemize}
    \item \textbf{Sinais de entrada}: Constituem-se os sinais, ou valores, externos ao modelo, muitas vezes submetidos a algum tratamento prévio, responsáveis por alimentar a rede.
    \item \textbf{Pesos sinápticos}: Também chamados apenas de pesos, ponderam os sinais de cada entrada da rede.
    \item \textbf{Combinador linear}: Operação aritmética envolvendo os sinais de entrada a fim de gerar um potencial de ativação.
    \item \textbf{Bias}: O bias é um valor adicional que é somado à combinação linear das entradas antes de passar pela função de ativação, visando ajustá-la para que os dados melhor se adaptem à rede.
    \item \textbf{Limiar de ativação}: Também denominado threshold, determina o nível adequado em que o resultado obtido pelo combinador linear pode acionar a ativação.
    \item \textbf{Potencial de ativação}: É o resultado decorrente da discrepância entre o valor gerado pelo combinador linear e o limiar de ativação. Se esse resultado for positivo, indicando \(u \geq 0\), o neurônio gera um potencial de excitação; caso contrário, o potencial será inibitório.
    \item \textbf{Função de ativação}: Sua função é restringir a saída de um neurônio dentro de um determinado intervalo de valores.
    \item \textbf{Sinal de saída}: Resultado final da saída, que pode ser utilizado como entrada para outros neurônios interligados sequencialmente.
  \end{itemize}  

Em suma, a RNA, enquanto um conjunto de NA, pode ser entendido como um processador robusto, distribuído de maneira paralela, com pequenas unidades de processamento. Sua semelhança ao cérebro humano, deve-se, portanto, à capacidade de aprendizado e aos sinais sinápticos, existentes entre os neurônios, responsáveis pelo processo de armazenamento de conhecimento \cite{haykin2001redes}.
	
De acordo com  \cite{rauber2005redes}, em 1958, após à concepção do NA, a primeira RNA a se notabilizar e a continuar sendo utilizada até o presente momento trata-se da Perceptron \cite{rosenblatt1958perceptron}. Este algoritmo possuía a capacidade de alterar os pesos dos neurônios, conforme o avanço do processamento da rede, de modo a resolver problemas resolvendo classificação linear. Seguido a ela, em 1960, houve a concepção da rede Adaline \cite{widrow1960adaptive}. Diferentemente da perceptron, esta rede já se mostrava capaz de produzir resultados que iam além dos valores binários, sendo capaz de gerar respostas de valores presentes em todo o conjunto dos números reais. O cálculo da rede Adaline era baseado na regra Delta, que era capaz de aproximar os valores dos pesos gerados para aqueles valores com menor erro possível. Ambas as redes, contudo, apresentavam uma limitação quanto à modificação dos pesos em todas suas multicamadas. Para esse cenário, foi proposto o conceito de backpropagation, ou, em tradução livre, retropropagação do erro \cite{rumelhart1986learning}. A ideia da retropropagação se inicia com o feedforward, em que todos os dados de entrada de uma RNA são transmitidos do início à camada de saída, sem nenhuma alteração de peso. Desta forma, calcula-se o erro total dessa primeira passagem, comparando o valor resultante com o esperado. Essa métrica de erro torna-se o guia para o ajuste dos pesos entre as conexões de cada neurônio. Com ela, é feito o caminho de volta, e calculado um gradiente de erro, que será o fator decisivo para a atualização dos pesos durante todo o treinamento.

A topologia básica de uma rede neural é dividida em três níveis de camada: a camada de entrada, a camada oculta e a camada de saída, conforme mostrado na figura \ref{fig:topologia}. A camada de entrada é, naturalmente, aquela que recebe os dados de entrada. Nela, cada nó representa uma característica ou atributo dos dados que estão sendo alimentados na rede neural. Por exemplo, em uma aplicação de reconhecimento de imagens, cada nó na camada de entrada pode representar um pixel da imagem. A camada oculta, que não se restringe a apenas uma, podendo ser várias, representa um processo intermediário entre a camada de entrada e a camada de saída. Cada neurônio em uma camada oculta recebe entradas das camadas anteriores, realiza algum tipo de transformação não linear dessas entradas e passa o resultado para a próxima camada. A presença de múltiplas camadas ocultas permite que a rede aprenda representações complexas e abstratas dos dados. Por bim, a camada de saída representa a camada final, e ela é responsável por gerar as saídas desejadas. A estrutura da camada de saída depende do tipo de problema que está sendo resolvido. Por exemplo, em um problema de classificação, cada nó na camada de saída pode representar uma classe diferente, e a saída pode ser interpretada como a probabilidade de pertencer a cada classe \cite{rauber2005redes}.

\begin{figure}[!h]
    \centering
    \begin{minipage}{0.9\linewidth}
    \centering
    \captionsetup{justification=centering,margin=0.5cm,font=small}
    \includegraphics[width=0.7\linewidth]{img/cap2/topologia-rede.jpeg}
    \caption{Topologia básica de uma rede neural \cite{fleck2016redes}}.
    \label{fig:topologia}
    \end{minipage}
\end{figure}

Essencialmente, as redes neurais aprendem iterativamente ajustando os pesos de suas conexões através do processo de treinamento, onde são apresentados a um conjunto de dados de entrada e as correspondentes saídas desejadas. Com o tempo, a rede neural é capaz de aprender a mapear efetivamente os padrões nos dados de entrada para as saídas desejadas, tornando-se assim capaz de realizar tarefas como reconhecimento de padrões, classificação, regressão, entre outros \cite{haykin2001redes}.

Contudo, para problemas envolvendo aprendizado por meio de imagens, a forma de lidar com as informações é diferente. De fato, imagens são dados, organizados em formato de matrizes de duas dimensões ou três dimensões (se for considerada a camada de cores), em que cada unidade de informação se chama pixel. Para processar esses dados, um tipo de RNA destaca-se: a Rede Neural Convolucional (RNC). Comparando ambas, nota-se que a RNA é composta por camadas intrinsecamente conectadas, em que cada neurônio de uma camada se conecta a todos os neurônios da camada seguinte. Isso faz com que ela seja adequada para dados vetorizados e para problemas de classificação e regressão sem uma estrutura espacial ou temporal específica. Por sua vez, a RNC recorre a dois tipos de camadas: a convolucional, cujo objetivo é extrair características locais, e a de pooling, responsável por manter a estrutura espacial essencial \cite{vargas2016estudo}. 

A camada de convolução, portanto, é responsável pela feature extractor, i.e., pela extração de características de interesse em uma imagem. Basicamente, são aplicados filtros, também chamados de kernel, a imagem a fim de buscar padrões. São comumente empregados filtros de detecção de bordas (edge detection), desfoque (blur), nitidez (sharpen). Conforme na figura \ref{fig:filtro}, cada elemento do filtro é multiplicado pelo elemento de mesma posição na região em que o filtro está sendo aplicado naquele instante. Ao final dessas operações matriciais, adiciona-se os resultados dessas multiplicações para ter um único valor como saída, que será o pixel correspondente na imagem filtrada. A camada pooling é utilizada após camadas convolucionais. Ela reduz as dimensões das imagens, mantendo a profundidade do volume (número de canais). Após as camadas convolucionais, é comum empregar a camada de pooling, que reduz as dimensões das imagens, mantendo a profundidade do volume. A técnica mais comum é o Max-pooling, onde, aplicando conceitos de stride e campo receptivo, seleciona-se o valor máximo dentro de uma região específica. Esse processo promove a invariância da RNC a transformações geométricas, permitindo à rede identificar objetos na imagem independentemente de sua posição. Além disso, contribui para diminuir significativamente o custo computacional da rede \cite{rodrigues2023visao}.

\begin{figure}[!h]
    \center
    \begin{minipage}{0.9\linewidth}
    \center
    \captionsetup{justification=centering,margin=0.5cm,font=small}
    \includegraphics[width=0.7\linewidth]{img/cap2/filtro.png}
    \caption{ Operação de filtragem na camada convolucional \cite{shorthistory}} 
    \label{fig:filtro}
    \end{minipage}
\end{figure}



\begin{figure}[!h]
    \centering
    \begin{minipage}{0.9\linewidth}
    \centering
    \captionsetup{justification=centering,margin=0.5cm,font=small}
    \includegraphics[width=0.7\linewidth]{img/cap2/cnn.jpeg}
    \caption{Esquema de funcionamento de uma RNC \cite{vargas2016estudo}}.
    \label{fig:rnc}
    \end{minipage}
\end{figure}

\subsection{You Look Only Once}
\label{sec:yolo}

YOLO (You Only Look Once) é um modelo de detecção de objetos em imagens e vídeos em tempo real, que se destaca por sua eficiência e precisão. Desenvolvido por Joseph Redmon, Santosh Divvala, Ross Girshick e Ali Farhadi, o YOLO aborda o problema de detecção de objetos como uma única tarefa de regressão, prevendo caixas delimitadoras e probabilidades de classe diretamente de imagens inteiras em uma única passagem pela rede neural. O funcionamento do YOLO começa com a divisão da imagem de entrada em uma grade, geralmente de dimensões como 7x7 ou 9x9. Cada célula dessa grade é responsável por prever um conjunto de caixas delimitadoras e as probabilidades das classes dos objetos contidos nessa célula. Para cada célula da grade, o modelo faz previsões sobre as caixas delimitadoras que contêm objetos, representadas por cinco valores: coordenadas (x, y) do centro da caixa, largura (w) e altura (h) da caixa, e a confiança de que a caixa contém um objeto. Além disso, são previstas as probabilidades de cada classe para cada caixa delimitadora. Após a predição das caixas delimitadoras, o YOLO utiliza um processo chamado Non-max Suppression (Supressão de Não-Máximo) para refinar as previsões e eliminar caixas sobrepostas ou redundantes, mantendo apenas as detecções mais confiáveis. Esse processo envolve a supressão de caixas que têm uma sobreposição significativa e a escolha da caixa com a maior confiança entre as caixas sobrepostas. A saída do YOLO é uma lista de caixas delimitadoras, cada uma associada a uma classe prevista e sua confiança. Essas caixas delimitadoras representam os objetos detectados na imagem, fornecendo informações sobre sua localização e classificação. Em resumo, o YOLO oferece uma abordagem eficaz e eficiente para a detecção de objetos em tempo real, consolidando-se como uma ferramenta valiosa em diversas aplicações, desde sistemas de segurança até veículos autônomos \cite{redmon2016youlookonce}.


\subsection{Batch}
\label{sec:batch}

Um dos aspectos cruciais do funcionamento da YOLO é o conceito de "batch" (em tradução livre, "lote") durante o treinamento da rede neural. Ao agrupar várias imagens em lotes para processamento simultâneo, a YOLO aproveita a capacidade de processamento paralelo das GPUs, acelerando significativamente o treinamento. Durante a propagação direta, cada imagem no lote é processada pela rede neural para gerar previsões de detecção de objetos. Em seguida, a perda é calculada em relação às anotações verdadeiras, e os pesos da rede são atualizados para minimizar essa perda, usando algoritmos de otimização como o gradiente descendente. Esse processo é repetido para vários lotes de imagens até que a rede convirja para uma solução adequada. Assim, o uso eficiente de lotes na YOLO não apenas acelera o treinamento, mas também contribui para a robustez e eficácia dos modelos de detecção de objetos resultantes. \cite{goodfellow2016deep}

\subsection{Otimizadores}
\label{sec:otimizadores}

Falar sobre o Otimizadores....!!!

\subsection{Precisão e Recall}
\label{sec:precisaorecall}

A fim de avaliar o desempenho de um treinamento na arquitetura YOLO, é preciso entender os resultados fornecidos pelo modelo. De acordo com \cite{padilla2020survey}, basicamente a YOLO utiliza a métrica chamada Average Precision (AP) (“Precisão Média”, em tradução livre). Ela se baseia no conceito de IoU (“Intersection over the Union”, Intersecção sobre a União, em tradução livre), que calcula uma razão entre a interseção da detecção feita pelo algoritmo com relação à marcação (bounding box) realizada em cima da área dividida pela união dessas duas áreas (Figura 1). Essa razão poderá ser comparada com um valor pré-estabelecido, o thresholds, que será referido por L. A partir desse valor, é possível que no processo de detecção retorne três diferentes resultados na pesquisa pela classe desejada. São eles: Verdadeiro Positivo (VP), Falso Positivo (FP) e Falso Negativo (FN). VP trata-se dos resultados considerados corretos que a rede neural retorna, que seriam todos resultados que IoU > L. FP já seriam os resultados em que IoU < L, que são tidos como incorretos.FN, por sua vez, trata dos resultados totalmente fora do esperado.

\begin{equation}
    \text{Recall} = \frac{VP}{VP + FN} \tag{1}
\end{equation}
    
\begin{equation}
    \text{Precisão} = \frac{VP}{VP + FP} \tag{2}
\end{equation}

Com esses valores, pode-se calcular os resultados da saída que o treinamento da rede YOLO fornece. Em (1), tem-se o cálculo da Recall, que calcula a capacidade da rede de detectar todos os objetos relevantes em uma imagem. Já a Precisão (2), refere-se à capacidade da rede de encontrar apenas resultados relevantes. 

%https://medium.com/@augusto_Pinheiro/redes-neurais-artificiais-133de77c7240
\begin{figure}[!h]
    \center
    \begin{minipage}{0.6\linewidth}
    \center
    \captionsetup{justification=centering,margin=0.5cm,font=small}
    \includegraphics[width=0.7\linewidth]{img/cap2/iou.png}
    \caption{ Cálculo de IoU. \cite{padilla2020survey}} \label{subfig:iou}
    \end{minipage}
\end{figure}

A arquitetura YOLO disponibiliza um dataset, ou seja, um banco de imagens e weights, comum em todas as versões, chamado de COCO (“Common Objects in Context”, que em tradução livre seria “Classes Comuns de Objetos”) com classes pré-treinadas e imagens para realização de treinamentos. A partir dele, verificou-se por meio de testes a eficiência das quatro últimas versões da YOLO, a fim de identificar se nas mais recentes houve melhoras significativas em termos de performance e precisão. Na Figura 1, é apresentado o comparativo das versões. Nota-se que a v8, para um menor número de parâmetros que as demais, apresentou uma mAP50-95, maior que nas versões v5, v6 e v7. Além disso, com relação a velocidade de processamento, a v8 também se sobressai, com maior rapidez no processamento, ao processar maior quantidade de imagens para um mesmo intervalo de tempo \cite{padilla2020survey}.

\begin{figure}[!h]
    \center
    \begin{minipage}{0.9\linewidth}
    \center
    \captionsetup{justification=centering,margin=0.5cm,font=small}
    \includegraphics[width=0.7\linewidth]{img/cap2/precisao.png}
    \caption{ Aumento de desempenho da precisão média, versão 5 para 8.  \cite{ultralytics2023yolo}} \label{subfig:precisao}
    \end{minipage}
\end{figure}

\section{Realidade Virtual}
\label{sec:precisaorecall}

RV pode ser definida como um ambiente gerado a partir de um sistema computacional em que o usuário não apenas se sente dentro do contexto artificial, como também possibilita ao usuário a consciência de que pode navegar e interagir neste ambiente virtual. Trata-se, por isso, de uma interessante interface em um ser humano, um computador, capaz de gerar navegabilidade, interações e, principalmente, imersão em um ambiente sintético, gerado computacionalmente por meio de canais multisensoriais. Além disso, a RV pode ser classificada de duas formas diferentes: Imersiva e Não-imersiva. Na primeira, cria-se uma RV que isole o usuário do mundo real. Seus sentidos são bloqueados para recepção dos estímulos do seu entorno, para se direcionarem àqueles oriundos do mundo fictício. Para tanto, uma ampla variedade de equipamentos, como fones de ouvidos, luvas de dados, óculos de RV, entre outros, são empregados para os resultados esperados. Já a RV Não-Imersiva não se isola do mundo real. Ou seja, o usuário tem consciência de que está em um ambiente artificial. Da mesma forma, uma ampla variedade de equipamentos é empregada para gerar essa interação, incluindo dispositivos do cotidiano, como mouses, monitores de computador. Uma grande variedade de dispositivos convencionais e não-convencionais pode compor  essa interação \cite {cardoso2007tecnologias}.

É importante que os três conceitos da RV sempre sejam presentes em uma aplicação do tipo, sendo eles: interação, imersão e navegação \cite{kalawsky1993science}.

O surgimento da RV data de 1963, em que foi apresentado uma aplicação de manipulação de objetos tridimensionais em um computador, denominada Sketchpad \cite {sutherland1963sketchpad}. A aplicação conseguia reproduzir interatividade por meio de uma caneta óptica, que era utilizada para seleção de objetos projetados em uma tela. Neste trabalho, surgiram alguns dos principais termos da RV, como representação visual, dispositivos especiais, e interações em tempo real. Em 1968, o mesmo autor do trabalho anterior, Sutherland, publicou outro trabalho marcante para a história: A Head-Mounted Three Dimensional Display \cite{sutherland1968head}. Nele, foi introduzido o conceito de imersividade para uma RV; no caso, um capacete capaz de projetar fotos diretamente aos olhos do usuário, assim como rastrear o movimento da cabeça, afim de que este movimento fosse responsivo no ambiente virtual. Seguido a isso, uma série de outros equipamentos foram desenvolvidos a fim de sofisticar as soluções do ramo e propor novos modelos. A tendência sempre prevaleceu de surgir ferramentas mais simples e acessíveis ao usuário final \cite{kirner2011evoluccao}.

Além das aplicações lúdicas, a RV atua de maneira séria e efetiva em diversas áreas técnicas. Como ferramenta para treinamento de operadores em ambientes de risco e de difícil simulação, torna-se uma alternativa viável para capacitação.  O trabalho de \cite{silva2012virtual} demonstra bem essa ideia ao investigar técnicas de RV para que uma pessoa comum, sem treinamento anterior, possa, de maneira segura à uma subestação em funcionamento e à própria pessoa e todos ao seu redor, interagir com um transformador de energia, executando todos procedimentos que teria em um ambiente real, contudo de maneira virtual. Este treinamento já seria uma base interessante para que um profissional pudesse agilizar seu treinamento no mundo real ou mesmo absorvê-los. Em trabalhos de alta periculosidade tudo é crítico; então, qualquer intervenção que possa atenuar os riscos inerentes à natureza do trabalho, traz grandes avanços ao processo de profissionalização de técnicos e pessoas interessadas. 


%Citar trabalho alexandre
%O artigo de kirner2011evoluccao, faz um panorama da história da realidade virtual.

\section{Considerações finais}

Neste capítulo, foi apresentado o arcabouço teórico necessário para o entendimento da proposta dessa dissertação. A apresentação das redes neurais, e em específico, o modo que a arquitetura da YOLOv8 sobrepõe-se em termos de eficiência em relação às demais arquiteturas abordadas em outros trabalhos científicos, demonstra o direcionamento assertivo deste trabalho. Além disso, a apresentação da Realidade Virtual como uma disciplina inovadora e muito útil para servir à diversos propósitos dentro da indústria e ciência, corroboram para o entendimento da proposta desta dissertação.